{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dHqQyxdiMpkp","executionInfo":{"status":"ok","timestamp":1715280159507,"user_tz":-120,"elapsed":26780,"user":{"displayName":"Luca Wiehe","userId":"05054678043137946684"}},"outputId":"586a9274-72e6-48d3-91f3-a27d351f7cad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","['.git', 'README.md', 'data', 'data_loader.ipynb', 'example_arrows', 'gitignore', 'open_nerf.ipynb']\n"]}],"source":["from google.colab import drive\n","import os\n","\n","# set path to project folder\n","gdrive_path='/content/gdrive/MyDrive/1-university/masters/2-semester/in2390_adl4cv/nerf_segmentation/' # Luca's Path\n","# gdrive_path='/content/gdrive/MyDrive/...' # Luis' Path\n","\n","# mount Google Drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# navigate to Google Drive folder\n","os.chdir(gdrive_path)\n","\n","# check that we are in the right folder\n","print(sorted(os.listdir()))"]},{"cell_type":"markdown","source":["Execute the following code from your machine's terminal:\n","```\n","git clone https://huggingface.co/datasets/YWjimmy/PeRFception-ScanNet\n","```\n","\n","Then compress the repository into a .zip-file and place it inside the `/data/` folder of this repository. This step is necessary to allow the execution of this notebook inside Google Colab. In our next step, we will unzip the file inside of this Colab session:\n"],"metadata":{"id":"WAGLCZ7P8RzS"}},{"cell_type":"code","source":["!unzip \"/content/gdrive/MyDrive/1-university/masters/2-semester/in2390_adl4cv/nerf_segmentation/data/PeRFception-ScanNet.zip\""],"metadata":{"id":"kHaG9PssQ3A7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714159409955,"user_tz":-120,"elapsed":64471,"user":{"displayName":"Luca Wiehe","userId":"05054678043137946684"}},"outputId":"cfed5bb5-b910-4e39-c49f-762f108b2a23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/gdrive/MyDrive/1-university/masters/2-semester/in2390_adl4cv/nerf_segmentation/data/PeRFception-ScanNet.zip\n","replace PeRFception-ScanNet/README.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","replace PeRFception-ScanNet/.gitattributes? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","replace PeRFception-ScanNet/plenoxel_scannet_scene0067_00/thick.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n","replace PeRFception-ScanNet/plenoxel_scannet_scene0067_00/last.ckpt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}]},{"cell_type":"markdown","source":["Additionally, you should place the train/val/test split files that were used in the original PeRFception paper. From the [NeRF-Downstream](https://github.com/POSTECH-CVLab/NeRF-Downstream) repository, you should install the following files from the `/co3d_3d/datasets/splits/` directory and place them inside `/data/split/`: `scannetv2_train`, `scannetv2_val`, `scannetv2_test`. Additionally, make sure to put the `scene_scales.data` file in that folder as well.\n","\n","Btw. I haven't checked the exact difference between `co3d_3d` and `co3d_2d` repository. I first wanted to get the code running in some way."],"metadata":{"id":"Od6pmujHtm5E"}},{"cell_type":"code","source":["!python -m pip install --upgrade pip setuptools wheel\n","!python -m pip install --upgrade pip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sj6GZVCs3G1W","executionInfo":{"status":"ok","timestamp":1714247060940,"user_tz":-120,"elapsed":22672,"user":{"displayName":"Luca Wiehe","userId":"05054678043137946684"}},"outputId":"108323eb-86eb-46a5-a37a-1b29ea657aeb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (69.5.1)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.43.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!python -m pip install torch torchvision torchaudio plyfile MinkowskiEngine\n","\n","# note: it is normal that building wheels for MinkowskiEngine takes about 15min"],"metadata":{"id":"HAEoIcqf3Eqy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714247733611,"user_tz":-120,"elapsed":672688,"user":{"displayName":"Luca Wiehe","userId":"05054678043137946684"}},"outputId":"0dc7ed98-d8e5-448d-ff8c-5707db98c62d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Collecting plyfile\n","  Using cached plyfile-1.0.3-py3-none-any.whl.metadata (2.1 kB)\n","Collecting MinkowskiEngine\n","  Using cached MinkowskiEngine-0.5.4.tar.gz (246 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Using cached plyfile-1.0.3-py3-none-any.whl (23 kB)\n","Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Building wheels for collected packages: MinkowskiEngine\n","  Building wheel for MinkowskiEngine (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for MinkowskiEngine: filename=MinkowskiEngine-0.5.4-cp310-cp310-linux_x86_64.whl size=23444334 sha256=149b4dad1a0365984e8c2bd385d144037dfbe27ca5a10a0de4f5fd1077813a47\n","  Stored in directory: /root/.cache/pip/wheels/ea/76/b8/a3da27f2079bdb9862105d604e40dd4326d4898b289eaad904\n","Successfully built MinkowskiEngine\n","Installing collected packages: plyfile, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, MinkowskiEngine\n","Successfully installed MinkowskiEngine-0.5.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 plyfile-1.0.3\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"3ppI_AhQWoa3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["MinkowskiEngine is not compatible with Python3.10. You have to go to `/usr/local/lib/python3.10/dist-packages/MinkowskiEngine/` and adjust some packages to use updated imports for `Sequence` that was previously part of `collections` and is now part of `collections.abc` as mentioned here: https://github.com/NVIDIA/MinkowskiEngine/issues/526"],"metadata":{"id":"Qqv3CuU3OB_W"}},{"cell_type":"code","source":["CLASS_LABELS = (\n","    \"wall\",\n","    \"floor\",\n","    \"cabinet\",\n","    \"bed\",\n","    \"chair\",\n","    \"sofa\",\n","    \"table\",\n","    \"door\",\n","    \"window\",\n","    \"bookshelf\",\n","    \"picture\",\n","    \"counter\",\n","    \"desk\",\n","    \"curtain\",\n","    \"refrigerator\",\n","    \"shower curtain\",\n","    \"toilet\",\n","    \"sink\",\n","    \"bathtub\",\n","    \"otherfurniture\",\n",")\n","\n","VALID_CLASS_IDS = (\n","    1,\n","    2,\n","    3,\n","    4,\n","    5,\n","    6,\n","    7,\n","    8,\n","    9,\n","    10,\n","    11,\n","    12,\n","    14,\n","    16,\n","    24,\n","    28,\n","    33,\n","    34,\n","    36,\n","    39,\n",")\n","\n","CLASS_LABELS_INSTANCE = (\n","    \"cabinet\",\n","    \"bed\",\n","    \"chair\",\n","    \"sofa\",\n","    \"table\",\n","    \"door\",\n","    \"window\",\n","    \"bookshelf\",\n","    \"picture\",\n","    \"counter\",\n","    \"desk\",\n","    \"curtain\",\n","    \"refrigerator\",\n","    \"shower curtain\",\n","    \"toilet\",\n","    \"sink\",\n","    \"bathtub\",\n","    \"otherfurniture\",\n",")\n","\n","VALID_CLASS_IDS_INSTANCE = (\n","    3,\n","    4,\n","    5,\n","    6,\n","    7,\n","    8,\n","    9,\n","    10,\n","    11,\n","    12,\n","    14,\n","    16,\n","    24,\n","    28,\n","    33,\n","    34,\n","    36,\n","    39,\n",")\n","\n","SCANNET_COLOR_MAP = {\n","    0: (0.0, 0.0, 0.0),\n","    1: (174.0, 199.0, 232.0),\n","    2: (152.0, 223.0, 138.0),\n","    3: (31.0, 119.0, 180.0),\n","    4: (255.0, 187.0, 120.0),\n","    5: (188.0, 189.0, 34.0),\n","    6: (140.0, 86.0, 75.0),\n","    7: (255.0, 152.0, 150.0),\n","    8: (214.0, 39.0, 40.0),\n","    9: (197.0, 176.0, 213.0),\n","    10: (148.0, 103.0, 189.0),\n","    11: (196.0, 156.0, 148.0),\n","    12: (23.0, 190.0, 207.0),\n","    14: (247.0, 182.0, 210.0),\n","    15: (66.0, 188.0, 102.0),\n","    16: (219.0, 219.0, 141.0),\n","    17: (140.0, 57.0, 197.0),\n","    18: (202.0, 185.0, 52.0),\n","    19: (51.0, 176.0, 203.0),\n","    20: (200.0, 54.0, 131.0),\n","    21: (92.0, 193.0, 61.0),\n","    22: (78.0, 71.0, 183.0),\n","    23: (172.0, 114.0, 82.0),\n","    24: (255.0, 127.0, 14.0),\n","    25: (91.0, 163.0, 138.0),\n","    26: (153.0, 98.0, 156.0),\n","    27: (140.0, 153.0, 101.0),\n","    28: (158.0, 218.0, 229.0),\n","    29: (100.0, 125.0, 154.0),\n","    30: (178.0, 127.0, 135.0),\n","    32: (146.0, 111.0, 194.0),\n","    33: (44.0, 160.0, 44.0),\n","    34: (112.0, 128.0, 144.0),\n","    35: (96.0, 207.0, 209.0),\n","    36: (227.0, 119.0, 194.0),\n","    37: (213.0, 92.0, 176.0),\n","    38: (94.0, 106.0, 211.0),\n","    39: (82.0, 84.0, 163.0),\n","    40: (100.0, 85.0, 144.0),\n","}\n","\n"],"metadata":{"id":"PjWAaLJV_hsg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","import numpy as np\n","import logging\n","import MinkowskiEngine as ME\n","from plyfile import PlyData\n","import pickle\n","from typing import List, Optional, Union\n","\n","def load_ply(filename, load_label=False, load_instance=False):\n","    plydata = PlyData.read(filename)\n","    data = plydata.elements[0].data\n","    coords = np.array([data[\"x\"], data[\"y\"], data[\"z\"]], dtype=np.float32).T\n","    feats = np.array([data[\"red\"], data[\"green\"], data[\"blue\"]], dtype=np.float32).T\n","    return_args = [coords, feats]\n","    if load_label:\n","        labels = np.array(data[\"label\"], dtype=np.int32)\n","        return_args.append(labels)\n","    if load_instance:\n","        instances = np.array(data[\"instance\"], dtype=np.int32)\n","    else:\n","        instances = np.ones(coords.shape[0], dtype=np.int32)\n","    return_args.append(instances)\n","    return tuple(return_args)\n","\n","class PlenoxelScannetDataset(Dataset):\n","\n","    NUM_LABELS = 41  # Will be converted to 20 as defined in IGNORE_LABELS.\n","    IGNORE_LABELS = tuple(set(range(NUM_LABELS)) - set(VALID_CLASS_IDS))\n","    IGNORE_LABELS_INSTANCE = tuple(\n","        set(range(NUM_LABELS)) - set(VALID_CLASS_IDS_INSTANCE)\n","    )\n","    CLASS_LABELS = CLASS_LABELS\n","    CLASS_LABELS_INSTANCE = CLASS_LABELS_INSTANCE\n","    VALID_CLASS_IDS = VALID_CLASS_IDS\n","\n","    DATA_PATH_FILE = {\n","        \"train\": \"scannetv2_train.txt\",\n","        \"val\": \"scannetv2_val.txt\",\n","        \"test\": \"scannetv2_test.txt\",\n","    }\n","    def __init__(\n","        self,\n","        phase: str,\n","        data_root: str = \"data/\",\n","        train_transformations=[],\n","        eval_transformations=[],\n","        downsample_mode=1,\n","        downsample_stride=2,\n","        voxel_size: float = 0.02,\n","        num_points: int = -1,\n","        features: List[str] = [\"sh\"],\n","        ignore_label: int = -100,\n","        void_label: Optional[int] = None,\n","        valid_thres: float = 0.05,\n","        ignore_thres: Optional[float] = None,\n","    ) -> None:\n","        Dataset.__init__(self)\n","        phase = \"test\" if phase in [\"val\", \"test\"] else \"train\"\n","        transformations = (\n","            train_transformations if phase == \"train\" else eval_transformations\n","        )\n","        #self.transformations = (\n","        #    transforms.Compose([transforms.__dict__[t]() for t in transformations])\n","        #    if len(transformations) > 0\n","        #    else None\n","        #)\n","        self.phase = phase\n","        self.data_root = data_root\n","        self.num_points = num_points\n","        self.features = features\n","        self.voxel_size = voxel_size\n","        self.ignore_label = ignore_label\n","        self.void_label = void_label if void_label is not None else ignore_label\n","        self.valid_thres = valid_thres\n","        self.ignore_thres = ignore_thres\n","        self.downsample_mode = downsample_mode\n","        self.downsample_stride = downsample_stride\n","\n","        with open(\n","            os.path.join(\n","                os.path.dirname(self.data_root), \"split\", self.DATA_PATH_FILE[phase]\n","            ),\n","            \"r\",\n","        ) as f:\n","            self.files = [l.strip(\"\\n\") for l in f.readlines() if not l.startswith(\"#\")]\n","\n","        if self.downsample_mode == 0:\n","            self.pool = ME.MinkowskiAvgPooling(\n","                kernel_size=self.downsample_stride,\n","                stride=self.downsample_stride,\n","                dimension=3,\n","            )\n","\n","        # map labels not evaluated to ignore_label\n","        label_map, n_used = dict(), 0\n","        for l in range(self.NUM_LABELS):\n","            if l in self.IGNORE_LABELS:\n","                label_map[l] = ignore_label\n","            else:\n","                label_map[l] = n_used\n","                n_used += 1\n","        label_map[ignore_label] = ignore_label\n","        if void_label is not None and void_label != ignore_label:\n","            label_map[void_label] = n_used\n","        self.label_map = label_map\n","\n","        with open(\n","            os.path.join(os.path.dirname(self.data_root), \"split\", \"scene_scales.data\"),\n","            \"rb\",\n","        ) as f:\n","            scene_scales = pickle.load(f)\n","        self.scene_scales = scene_scales\n","        logging.info(\n","            f\"{self.__class__.__name__}(phase={phase}, total size={len(self.files)}, num_classes={len(self.CLASS_LABELS)}, downsample stride={self.downsample_stride})\"\n","        )\n","\n","    def __len__(self):\n","        return len(self.pc_files)\n","\n","    def __getitem__(self, index) -> dict:\n","        inst_id = self.files[index]\n","\n","        data = self.load_data(inst_id)\n","        links, density, sh, reso, labels, dists = (\n","            data[\"links\"],\n","            data[\"density\"],\n","            data[\"sh\"],\n","            data[\"reso\"],\n","            data[\"labels\"],\n","            data[\"dists\"],\n","        )\n","        coordinates = torch.stack(\n","            [\n","                links // (reso[1] * reso[2]),\n","                links % (reso[1] * reso[2]) // reso[2],\n","                links % reso[2],\n","            ],\n","            1,\n","        ).float()\n","\n","        if len(self.features) > 1:\n","            density /= np.abs(density).max() + 1e-5\n","\n","        coordinates, dist_density_sh_label = self.downsample(\n","            coordinates, torch.cat([dists, density, sh, labels], dim=1)\n","        )\n","        norm_coordinates = coordinates / reso * 2 - 1.0\n","        scene_scale = self.scene_scales[inst_id]\n","        scaled_coordinates = norm_coordinates / scene_scale\n","        xyzs = scaled_coordinates / self.voxel_size\n","        labels = dist_density_sh_label[:, -1]\n","        dist_density_sh = dist_density_sh_label[:, :-1]\n","\n","        # normalize xyzs to fit in unit sphere\n","        # xyzs = coordinates - coordinates.mean(dim=1, keepdim=True)\n","        # max_norm = torch.linalg.norm(xyzs, dim=1).max()\n","        # xyzs = xyzs / max_norm\n","        raw_features = torch.cat([xyzs, dist_density_sh], dim=1).float()\n","\n","        xyzs = xyzs.numpy().astype(np.float32)\n","        raw_features = raw_features.numpy().astype(np.float32)\n","\n","        if self.transformations is not None:\n","            xyzs, raw_features, labels = self.transformations(\n","                xyzs, raw_features, labels\n","            )\n","\n","        dists = raw_features[:, 3:4]\n","        density = raw_features[:, 4:5]\n","        sh = raw_features[:, 5:]\n","        ones = np.ones(density.shape)\n","\n","        features = []\n","        for f in self.features:\n","            features.append(eval(f))\n","        features = np.concatenate(features, axis=1).astype(np.float32)\n","        if self.IGNORE_LABELS is not None:\n","            labels = np.array(\n","                [self.label_map[x] for x in labels.numpy()], dtype=np.int32\n","            )\n","\n","        return {\n","            \"coordinates\": xyzs.astype(np.float32),\n","            \"features\": features.astype(np.float32),\n","            \"xyzs\": xyzs,\n","            \"labels\": labels,\n","            \"dists\": dists,\n","            \"metadata\": {\"file\": self.files[index]},\n","        }\n","\n","    def downsample(self, coordinates, features):\n","        if self.downsample_mode == 0:\n","            bcoords = ME.utils.batched_coordinates([coordinates])\n","            stensor = ME.SparseTensor(features=features, coordinates=bcoords)\n","            output = self.pool(stensor)\n","            results = (output.C[:, 1:].float() / 2, output.F)\n","        elif self.downsample_mode == 1:\n","            sel = (coordinates % self.downsample_stride == 0).all(dim=1)\n","            # results = (coordinates[sel] / self.downsample_stride, features[sel])\n","            results = (coordinates[sel], features[sel])\n","        else:\n","            raise ValueError(f\"Downsample mode {self.downsample_mode} is invalid.\")\n","\n","        logging.debug(\n","            f\"voxel downsample with mode {self.downsample_mode} stride {self.downsample_stride}: from {coordinates.shape[0]} to {results[0].shape[0]}\"\n","        )\n","        return results\n","\n","    def load_data(self, inst_id):\n","        ckpt_path = os.path.join(\n","            self.data_root, \"scannet\", f\"plenoxel_scannet_{inst_id}\", \"data.npz\"\n","        )\n","        ckpt = np.load(ckpt_path)\n","        links = torch.from_numpy(ckpt[\"links\"])\n","        density = torch.from_numpy(ckpt[\"density\"])\n","        sh = ckpt[\"sh\"].astype(np.float32) * ckpt[\"sh_scale\"] + ckpt[\"sh_min\"]\n","        sh = torch.from_numpy(sh)\n","        reso = ckpt[\"reso\"]\n","        labels = torch.from_numpy(ckpt[\"labels\"]).unsqueeze(1)\n","\n","        dists = torch.from_numpy(ckpt[\"dists\"]).unsqueeze(1)\n","\n","        is_void = dists > self.valid_thres\n","        labels[is_void] = self.void_label\n","\n","        if self.ignore_thres is not None and self.ignore_thres > 0:\n","            valid = dists < self.ignore_thres\n","            links = links[valid]\n","            sh = sh[valid]\n","            density = density[valid]\n","            labels = labels[valid]\n","        return dict(\n","            links=links, density=density, sh=sh, reso=reso, labels=labels, dists=dists\n","        )"],"metadata":{"id":"HzDwpeiZnqhm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = PlenoxelScannetDataset(\n","        \"train\",\n","        \"./data/\",\n","        downsample_stride=2,\n","        void_label=-333,\n","        ignore_thres=0.20,\n","    )"],"metadata":{"id":"dfc6YYMrLwh7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Incompatibility of DataLoader with PeRFception Dataset\n","If you execute the following cell, you will see that loading the dataset is not successful. I have the suspicion that this is because `PlenoxelScannetDataset` is different from `PeRFception-Scannet` (i.e. the dataset they provide). The reason for this is that in `PlenoxelScannetDataset`, they try to access `data.npz` which is not part of the downloaded dataset. I am very confused because in the [PeRFception-Downstream](https://github.com/POSTECH-CVLab/NeRF-Downstream) repository, you can search for terms like \"PeRFception-Scannet\" and will find only a single occurence in the repository's `README.md`.\n","\n","What we will have to understand in order to keep working on this is the `/co3d_3d/src/modules/segmentation_training.py` file and how its components are spread throughout the repository."],"metadata":{"id":"Bs55OaTvaaQm"}},{"cell_type":"code","source":["print(dataset[0])"],"metadata":{"id":"pN0UWMKVXvtZ","colab":{"base_uri":"https://localhost:8080/","height":418},"executionInfo":{"status":"error","timestamp":1714252033128,"user_tz":-120,"elapsed":197,"user":{"displayName":"Luca Wiehe","userId":"05054678043137946684"}},"outputId":"139ca8f9-de06-4480-85c9-b56608e763d5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"UnpicklingError","evalue":"Failed to interpret file './data/scannet/plenoxel_scannet_scene0191_00/trans_info.npz' as a pickle","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-458771d72ad1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-21-abadcbb3a41d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0minst_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         links, density, sh, reso, labels, dists = (\n\u001b[1;32m    125\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"links\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-abadcbb3a41d>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(self, inst_id)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scannet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"plenoxel_scannet_{inst_id}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trans_info.npz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         )\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mlinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"links\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mdensity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"density\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 raise pickle.UnpicklingError(\n\u001b[0m\u001b[1;32m    468\u001b[0m                     f\"Failed to interpret file {file!r} as a pickle\") from e\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: Failed to interpret file './data/scannet/plenoxel_scannet_scene0191_00/trans_info.npz' as a pickle"]}]},{"cell_type":"markdown","source":["For now, let us ignore these issues and take a step back from their implementation. Let us first understand what information is accessible from the dataset."],"metadata":{"id":"ytoIfOGWfbpG"}},{"cell_type":"code","source":["import os\n","\n","scene_path = \"data/scannet/plenoxel_scannet_scene0001_01/\"\n","files = os.listdir(scene_path)\n","print(\"Files in directory:\", files)"],"metadata":{"id":"iOu7hGsGAtz5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714289836872,"user_tz":-120,"elapsed":194,"user":{"displayName":"Luca Wiehe","userId":"05054678043137946684"}},"outputId":"a072ebbd-bfb9-4370-c616-1fe7b47cc87d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files in directory: ['trans_info.npz', 'init.npy', 'render_model', 'results.json', 'config.gin', 'thick.npy', 'last.ckpt']\n"]}]},{"cell_type":"markdown","source":["Let's start by investigating `trans_info.npz`. As we can see, this file is an invalid `.zip`-file causing numpy to fail interpreting it."],"metadata":{"id":"4Cc3ovYoplbZ"}},{"cell_type":"code","source":["import numpy as np\n","import zipfile\n","\n","file_path = 'data/scannet/plenoxel_scannet_scene0001_01/trans_info.npz'\n","\n","# Check if the file is a valid ZIP file\n","if zipfile.is_zipfile(file_path):\n","    print(\"This is a valid ZIP file.\")\n","else:\n","    print(\"This is NOT a valid ZIP file.\")\n","\n","np.load(scene_path + \"trans_info.npz\", allow_pickle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":436},"id":"gGl2ejunkbso","executionInfo":{"status":"error","timestamp":1714290030969,"user_tz":-120,"elapsed":223,"user":{"displayName":"Luca Wiehe","userId":"05054678043137946684"}},"outputId":"18a96d2c-a802-4af7-b72d-34ac4b685d58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This is NOT a valid ZIP file.\n"]},{"output_type":"error","ename":"UnpicklingError","evalue":"Failed to interpret file 'data/scannet/plenoxel_scannet_scene0001_01/trans_info.npz' as a pickle","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-c1f0e354e44a>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"This is NOT a valid ZIP file.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"trans_info.npz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 raise pickle.UnpicklingError(\n\u001b[0m\u001b[1;32m    468\u001b[0m                     f\"Failed to interpret file {file!r} as a pickle\") from e\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: Failed to interpret file 'data/scannet/plenoxel_scannet_scene0001_01/trans_info.npz' as a pickle"]}]},{"cell_type":"markdown","source":["Next, we will investigate `init.npy`. We face the same issue here."],"metadata":{"id":"XmNIyiKtqBRT"}},{"cell_type":"code","source":["np.load(scene_path + \"init.npy\", allow_pickle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"av8GNArRovJM","executionInfo":{"status":"error","timestamp":1714290331479,"user_tz":-120,"elapsed":217,"user":{"displayName":"Luca Wiehe","userId":"05054678043137946684"}},"outputId":"c128259d-8e6c-4804-a23f-b5448799ebe5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"UnpicklingError","evalue":"Failed to interpret file 'data/scannet/plenoxel_scannet_scene0001_01/init.npy' as a pickle","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-d048b3d2b16e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"init.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 raise pickle.UnpicklingError(\n\u001b[0m\u001b[1;32m    468\u001b[0m                     f\"Failed to interpret file {file!r} as a pickle\") from e\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: Failed to interpret file 'data/scannet/plenoxel_scannet_scene0001_01/init.npy' as a pickle"]}]},{"cell_type":"markdown","source":["`/render_model/` is a directory with 2D images in `.jpg`-format inside. We will print the first three images as an example."],"metadata":{"id":"3OGtEusBqxtf"}},{"cell_type":"code","source":["files = os.listdir(scene_path + \"render_model/\")\n","print(\"Files in directory:\", files[:3])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8sCAMMqbqkb3","executionInfo":{"status":"ok","timestamp":1714290905018,"user_tz":-120,"elapsed":11,"user":{"displayName":"Luca Wiehe","userId":"05054678043137946684"}},"outputId":"e77d156e-fba3-48e1-9da1-930b37edb86f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files in directory: ['image016.jpg', 'image003.jpg', 'image000.jpg']\n"]}]},{"cell_type":"markdown","source":["For the next file `results.json`, one may assume that a `.json`-decoder would work because the authors encode the file as a `.json`. However, this does not work because it simply references a Github storage. Feel free to download files and play around with them."],"metadata":{"id":"3JXBKoIgt5LS"}},{"cell_type":"code","source":["with open(scene_path + \"results.json\", 'r') as file:\n","    snippet = file.read(100)  # Read the first 100 characters\n","    print(\"First 100 characters of the file:\\n\", snippet)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93TPyLSisyRC","executionInfo":{"status":"ok","timestamp":1714291257502,"user_tz":-120,"elapsed":206,"user":{"displayName":"Luca Wiehe","userId":"05054678043137946684"}},"outputId":"0a9e346d-381b-47e6-fb82-ea5fdd09eefa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["First 100 characters of the file:\n"," version https://git-lfs.github.com/spec/v1\n","oid sha256:4ec3e655ee92106f969ea942ab89587d67376eeb7255b9\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"LhLdIdlstUJN"},"execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":0}